{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from tensorflow.summary import FileWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "pca_t= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('ml-25m/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set:  9946\n",
      "Number of validation set:  1106\n",
      "Numebr of test set:  2764\n"
     ]
    }
   ],
   "source": [
    "#split data and labels \n",
    "X = df.drop(['rating'], axis=1)\n",
    "y = df['rating']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "#count the numebr of x_train x_val and x_test\n",
    "print(\"Number of train set: \", X_train.shape[0])\n",
    "print(\"Number of validation set: \", X_val.shape[0])\n",
    "print(\"Numebr of test set: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA is applied\n"
     ]
    }
   ],
   "source": [
    "if pca_t == True:\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    X_test = pca.transform(X_test)\n",
    "    print (\"PCA is applied\")\n",
    "else:\n",
    "    print (\"PCA is not applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione Lineare:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Senza PCA:**\n",
    "- Mean Squared Error: 0.00544\n",
    "- R2-Square: 0.97543\n",
    "\n",
    "**Con PCA:**\n",
    "- Mean Squared Error: 0.00643\n",
    "- R2-Square:  0.97096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO PCA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 0.00544540691904858\n",
      "R2-square: 0.9754341910082425\n"
     ]
    }
   ],
   "source": [
    "log_name = f\"linear_regression\"\n",
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"risultati/Machine_Learning_trad/pca/Linear_Regression/{log_name}\")\n",
    "    print(\"PCA\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"risultati/Machine_Learning_trad/no_pca/Linear_Regression/{log_name}\")\n",
    "    print(\"NO PCA\")\n",
    "\n",
    "lin_regr_model = linear_model.LinearRegression()\n",
    "lin_regr_model.fit(X_train, y_train)\n",
    "y_pred = lin_regr_model.predict(X_test)\n",
    "\n",
    "# Compute the RSS\n",
    "mse = mean_squared_error(y_test, y_pred) \n",
    "\n",
    "writer.add_scalar('Loss', mse)\n",
    "writer.flush()\n",
    "\n",
    "# Compute the R-square index\n",
    "rsquare = r2_score(y_test, y_pred) \n",
    "\n",
    "print('Mean Square Error:', mse)\n",
    "print('R2-square:', rsquare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no PCA**\n",
    "- MSE: 0.00531\n",
    "- R2-square: 0.97600\n",
    "\n",
    "**PCA**\n",
    "- Mean Squared Error: 0.00639\n",
    "- R2- Squared: 0.97114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miglior alpha trovato: 3\n"
     ]
    }
   ],
   "source": [
    "# Creazione del modello Ridge\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Definisci i parametri da cercare con la grid search\n",
    "param_grid= {'alpha':[0.0001, 0.001, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 10, 20]}\n",
    "\n",
    "# Creazione dell'oggetto di Grid Search con cross-validation\n",
    "grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "# Addestramento del modello sulla grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Estrai il miglior valore di alpha trovato\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "print(\"Miglior alpha trovato:\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO PCA\n"
     ]
    }
   ],
   "source": [
    "if pca_t == True:\n",
    "    writer = SummaryWriter(f\"tradML/risultati_cv/pca/Ridge_Regression/\")\n",
    "    print(\"PCA\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"tradML/risultati_cv/no_pca/Ridge_Regression/\")\n",
    "    print(\"NO PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['param_alpha', 'mean_test_score']]\n",
    "results['mean_test_score'] = results['mean_test_score'] * -1  # Inverti il segno dell'errore quadratico medio\n",
    "\n",
    "# Salva i risultati in TensorBoard\n",
    "if pca_t:\n",
    "    writer = SummaryWriter(f\"risultati/Machine_Learning_trad/pca/Ridge_Regression\")\n",
    "else:\n",
    "    writer = SummaryWriter(f\"risultati/Machine_Learning_trad/no_pca/Ridge_Regression/\")\n",
    "\n",
    "for index, row in results.iterrows():\n",
    "    mse = row['mean_test_score']\n",
    "    alpha = row['param_alpha']\n",
    "    writer.add_hparams({\"alpha\": alpha}, {\"mse\": mse})\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "ridge = ridge.T\n",
    "if pca_t == True:\n",
    "    ridge.to_csv('tradML/b_params/pca/ridge.csv', index=False)\n",
    "else:\n",
    "    ridge.to_csv('tradML/b_params/no_pca/ridge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE su dati di test: 0.005319102663833808\n",
      "R2 su dati di test: 0.9760039861134711\n"
     ]
    }
   ],
   "source": [
    "# Addestra il modello Ridge con il miglior alpha trovato sui dati di addestramento\n",
    "best_ridge_model = Ridge(alpha=best_alpha)\n",
    "best_ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Calcolo delle predizioni sui dati di test\n",
    "y_test_pred = best_ridge_model.predict(X_test)\n",
    "\n",
    "# Calcolo delle metriche di valutazione\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Stampa il miglior valore di alpha e le metriche di valutazione\n",
    "#print(\"Miglior alpha trovato:\", best_alpha)\n",
    "print(\"MSE su dati di test:\", mse_test)\n",
    "print(\"R2 su dati di test:\", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no PCA**\n",
    "- Mean Squared Error: 0.00542\n",
    "- R2- Squared: 0.97553\n",
    "\n",
    "**PCA**\n",
    "- Mean Squared Error:  0.00641\n",
    "- R2- Squared: 0.97106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model= Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.527e+00, tolerance: 1.880e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.996e+00, tolerance: 1.910e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.742e+00, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e+00, tolerance: 1.897e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.194e+00, tolerance: 1.885e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+01, tolerance: 1.880e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+01, tolerance: 1.910e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+01, tolerance: 1.920e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+01, tolerance: 1.897e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+01, tolerance: 1.885e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miglior hyperparametro Lasso(alpha=1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+01, tolerance: 2.373e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "param_grid= {'alpha': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]}\n",
    "grid_search= GridSearchCV(lasso_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_param= grid_search.best_estimator_\n",
    "print(\"Miglior hyperparametro\", best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/pca/lasso.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/no_pca/lasso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only neg_mean_squared_error and convert to positive\n",
    "results= pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['mean_test_score', 'param_alpha']]\n",
    "results['mean_test_score']= -1*results['mean_test_score']\n",
    "\n",
    "#save mse to tensorboard\n",
    "if pca_t == True:\n",
    "    writer= SummaryWriter(f'risultati/Machine_Learning_trad/pca/Lasso/')\n",
    "else:\n",
    "    writer= SummaryWriter(f'risultati/Machine_Learning_trad/no_pca/Lasso/')\n",
    "for i, rows in results.iterrows():\n",
    "    mse= rows['mean_test_score']\n",
    "    alpha= rows['param_alpha']\n",
    "    writer.add_hparams({'alpha': alpha}, {'mse': mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model= pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "lasso_model= lasso_model.T\n",
    "\n",
    "if pca_t == True:\n",
    "    lasso_model.to_csv('tradML/b_params/pca/lasso.csv', index=False)\n",
    "else:\n",
    "    lasso_model.to_csv('tradML/b_params/no_pca/lasso.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.005423553353396875\n",
      "R2 score:  0.9755327787772686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+01, tolerance: 2.373e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=best_param.alpha)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred = lasso_model.predict(X_test)   \n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score: \", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di featurs con coefficiente 0:  146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "007           -0.097706\n",
       "1920s          0.379278\n",
       "3d            -0.153728\n",
       "aardman        0.060788\n",
       "afterlife     -0.079177\n",
       "alcoholism     0.206545\n",
       "almodovar      0.083976\n",
       "amnesia        0.062696\n",
       "animation      0.024383\n",
       "arms dealer   -0.073337\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if pca_t == False:\n",
    "    #print null coefficients and name of lasso without pca\n",
    "    lasso_coeff= pd.DataFrame({'feature': X_train.columns, 'coefficient': lasso_model.coef_})\n",
    "    lasso_coeff= lasso_coeff[lasso_coeff['coefficient']==0]\n",
    "    print(\"Numero di featurs con coefficiente 0: \", lasso_coeff.shape[0])\n",
    "\n",
    "    lasso_coeff= pd.DataFrame({'feature': X_train.columns, 'coefficient': lasso_model.coef_})\n",
    "    lasso_coeff= lasso_coeff[lasso_coeff['coefficient']==0]\n",
    "    X_zero= lasso_coeff['feature'].tolist()\n",
    "    #correlarion between features set to 0 and y\n",
    "    corr= df[X_zero].corrwith(y)\n",
    "    display(corr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no PCA**\n",
    "- Mean Squared Error: 0.01272\n",
    "- R2-socore: 0.94260\n",
    "\n",
    "**PCA**\n",
    "- Mean Squared Error: 0.03801\n",
    "- R2-socore: 0.82850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ...........criterion=squared_error, n_estimators=10; total time=  58.8s\n",
      "[CV] END ...........criterion=squared_error, n_estimators=10; total time= 1.3min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=10; total time= 1.5min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=10; total time= 1.4min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=10; total time= 1.2min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=15; total time= 1.6min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=15; total time= 1.8min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=15; total time= 1.9min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=15; total time= 1.9min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=15; total time= 1.6min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=20; total time= 2.3min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=20; total time= 2.5min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=20; total time= 2.1min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=20; total time= 2.0min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=20; total time= 2.6min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=25; total time= 2.6min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=25; total time= 2.5min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=25; total time= 2.5min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=25; total time= 2.3min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=25; total time= 2.5min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=30; total time= 3.1min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=30; total time= 2.8min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=30; total time= 2.8min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=30; total time= 2.5min\n",
      "[CV] END ...........criterion=squared_error, n_estimators=30; total time= 2.6min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=10; total time= 1.1min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=10; total time= 1.1min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=10; total time= 1.1min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=10; total time= 1.0min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=10; total time= 1.0min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=15; total time= 1.5min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=15; total time= 1.5min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=15; total time= 1.5min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=15; total time= 1.5min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=15; total time= 1.9min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=20; total time= 2.6min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=20; total time= 2.8min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=20; total time= 2.8min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=20; total time= 2.7min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=20; total time= 2.8min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=25; total time= 3.6min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=25; total time= 3.5min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=25; total time= 3.8min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=25; total time= 3.4min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=25; total time= 3.5min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=30; total time= 4.1min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=30; total time= 4.3min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=30; total time= 4.1min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=30; total time= 3.8min\n",
      "[CV] END ............criterion=friedman_mse, n_estimators=30; total time= 3.8min\n"
     ]
    }
   ],
   "source": [
    "rf= RandomForestRegressor()\n",
    "\n",
    "param_grid= {\n",
    "    'n_estimators': [10, 15, 20, 25, 30],\n",
    "    'criterion': ['squared_error', 'friedman_mse'],\n",
    "}\n",
    "\n",
    "grid_search= GridSearchCV(estimator= rf, param_grid= param_grid, cv=5, scoring='neg_mean_squared_error', verbose= 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_param= grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miglior hyperparametro RandomForestRegressor(n_estimators=30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Miglior hyperparametro\", best_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/pca/random_forest.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/no_pca/random_forest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(grid_search.cv_results_)\n",
    "results= results[['mean_test_score', 'param_n_estimators', 'param_criterion']]\n",
    "results['mean_test_score']= -1*results['mean_test_score']\n",
    "\n",
    "if pca_t == True:\n",
    "    writer= SummaryWriter(f'risultati//Machine_Learning_trad/pca/Random_Forest/')\n",
    "else:\n",
    "    writer= SummaryWriter(f'risultati//Machine_Learning_trad/no_pca/Random_Forest/')\n",
    "for i, rows in results.iterrows():\n",
    "    mse= rows['mean_test_score']\n",
    "    n_estimators= rows['param_n_estimators']\n",
    "    criterion= rows['param_criterion']\n",
    "    writer.add_hparams({'n_estimators': n_estimators, 'criterion': criterion}, {'mse': mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "rf= rf.T\n",
    "if pca_t == True:\n",
    "    rf.to_csv('tradML/b_params/pca/random_forest.csv', index=False)\n",
    "else:\n",
    "    rf.to_csv('tradML/b_params/no_pca/random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.012343934174509526\n",
      "R2 score:  0.9443129349843314\n"
     ]
    }
   ],
   "source": [
    "rf= RandomForestRegressor(n_estimators= best_param.n_estimators, criterion= best_param.criterion)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred= rf.predict(X_test)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stampare le 10 features pi importanti con random forest\n",
    "if pca_t == False:\n",
    "    feature_importance = rf.feature_importances_\n",
    "    importance_df= pd.DataFrame({'feature': X_train.columns, 'importance': feature_importance})\n",
    "    importance_df= importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.barplot(x='importance', y='feature', data=importance_df.head(10), palette='Greens_r')\n",
    "    plt.title('Feature importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"PCA is applied, no feature importance to show\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no PCA**\n",
    "- Mean Squared Error: 0.04049\n",
    "- R2-socore: 0.81729\n",
    "  \n",
    "**PCA**\n",
    "- Mean Squared Error: 0.04015\n",
    "- R2-socore: 0.81883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=   1.6s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=   1.8s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=   1.6s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=   1.3s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=   1.7s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=   1.8s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=   1.1s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=   1.2s\n",
      "[CV] END .....................n_neighbors=9, weights=uniform; total time=   1.2s\n",
      "[CV] END .....................n_neighbors=9, weights=uniform; total time=   1.7s\n",
      "[CV] END .....................n_neighbors=9, weights=uniform; total time=   1.7s\n",
      "[CV] END .....................n_neighbors=9, weights=uniform; total time=   1.6s\n",
      "[CV] END .....................n_neighbors=9, weights=uniform; total time=   1.3s\n",
      "[CV] END ....................n_neighbors=9, weights=distance; total time=   1.4s\n",
      "[CV] END ....................n_neighbors=9, weights=distance; total time=   1.4s\n",
      "[CV] END ....................n_neighbors=9, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=9, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=9, weights=distance; total time=   1.6s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   2.0s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   1.3s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   1.3s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   1.3s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   1.7s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   1.1s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   1.7s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   1.4s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   1.3s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   1.4s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   1.4s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   1.6s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   1.9s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   2.1s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   3.8s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   2.4s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   1.4s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   3.8s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   3.2s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   2.1s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   1.7s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   1.3s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   1.3s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   1.3s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   1.1s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   1.3s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   1.2s\n",
      "Miglior hyperparametro {'n_neighbors': 11, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knn= KNeighborsRegressor()\n",
    "\n",
    "param_grid= {\n",
    "    'n_neighbors': [7, 9, 11, 13, 15, 17, 19, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "grid_search= GridSearchCV(estimator= knn, param_grid= param_grid, cv=5, scoring='neg_mean_squared_error', verbose= 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_param= grid_search.best_params_\n",
    "print(\"Miglior hyperparametro\", best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/pca/knn.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/no_pca/knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(grid_search.cv_results_)\n",
    "results= results[['mean_test_score', 'param_n_neighbors', 'param_weights']]\n",
    "results['mean_test_score']= -1*results['mean_test_score']\n",
    "\n",
    "if pca_t == True:\n",
    "    writer= SummaryWriter(f'risultati//Machine_Learning_trad/pca/KNN/')\n",
    "else:\n",
    "    writer= SummaryWriter(f'risultati//Machine_Learning_trad/no_pca/KNN/')\n",
    "\n",
    "for i, rows in results.iterrows():\n",
    "    mse= rows['mean_test_score']\n",
    "    n_neighbors= rows['param_n_neighbors']\n",
    "    weights= rows['param_weights']\n",
    "    writer.add_hparams({'n_neighbors': n_neighbors, 'weights': weights}, {'mse': mse})\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn= pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "knn= knn.T\n",
    "if pca_t == True:\n",
    "    knn.to_csv('tradML/b_params/pca/knn.csv', index=False)\n",
    "else:\n",
    "    knn.to_csv('tradML/b_params/no_pca/knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.04049981997445227\n",
      "R2 score:  0.8172935730087196\n"
     ]
    }
   ],
   "source": [
    "knn= KNeighborsRegressor(n_neighbors= best_param['n_neighbors'], weights= best_param['weights'])\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred= knn.predict(X_test)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no PCA:**\n",
    "- MSE: \n",
    "- R2-Square: \n",
    "\n",
    "**PCA:**\n",
    "- MSE: 0.00659\n",
    "- R2-Square: 0.97022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.001, epsilon=0.001, kernel=poly; total time=  46.8s\n",
      "[CV] END ................C=0.001, epsilon=0.001, kernel=poly; total time=  53.9s\n",
      "[CV] END ................C=0.001, epsilon=0.001, kernel=poly; total time=  45.6s\n",
      "[CV] END ................C=0.001, epsilon=0.001, kernel=poly; total time=  35.5s\n",
      "[CV] END ................C=0.001, epsilon=0.001, kernel=poly; total time=  34.7s\n",
      "[CV] END .................C=0.001, epsilon=0.001, kernel=rbf; total time=  36.5s\n",
      "[CV] END .................C=0.001, epsilon=0.001, kernel=rbf; total time=  44.4s\n",
      "[CV] END .................C=0.001, epsilon=0.001, kernel=rbf; total time=  36.5s\n",
      "[CV] END .................C=0.001, epsilon=0.001, kernel=rbf; total time=  42.9s\n",
      "[CV] END .................C=0.001, epsilon=0.001, kernel=rbf; total time=  43.9s\n",
      "[CV] END .............C=0.001, epsilon=0.001, kernel=sigmoid; total time=  39.8s\n",
      "[CV] END .............C=0.001, epsilon=0.001, kernel=sigmoid; total time=  44.8s\n",
      "[CV] END .............C=0.001, epsilon=0.001, kernel=sigmoid; total time=  49.4s\n",
      "[CV] END .............C=0.001, epsilon=0.001, kernel=sigmoid; total time=  40.2s\n",
      "[CV] END .............C=0.001, epsilon=0.001, kernel=sigmoid; total time=  38.2s\n",
      "[CV] END .................C=0.001, epsilon=0.01, kernel=poly; total time=  38.3s\n",
      "[CV] END .................C=0.001, epsilon=0.01, kernel=poly; total time=  34.1s\n",
      "[CV] END .................C=0.001, epsilon=0.01, kernel=poly; total time=  32.8s\n",
      "[CV] END .................C=0.001, epsilon=0.01, kernel=poly; total time=  32.8s\n",
      "[CV] END .................C=0.001, epsilon=0.01, kernel=poly; total time=  37.1s\n",
      "[CV] END ..................C=0.001, epsilon=0.01, kernel=rbf; total time=  31.3s\n",
      "[CV] END ..................C=0.001, epsilon=0.01, kernel=rbf; total time=  31.3s\n",
      "[CV] END ..................C=0.001, epsilon=0.01, kernel=rbf; total time=  39.6s\n",
      "[CV] END ..................C=0.001, epsilon=0.01, kernel=rbf; total time=  38.1s\n",
      "[CV] END ..................C=0.001, epsilon=0.01, kernel=rbf; total time=  36.6s\n",
      "[CV] END ..............C=0.001, epsilon=0.01, kernel=sigmoid; total time=  34.6s\n",
      "[CV] END ..............C=0.001, epsilon=0.01, kernel=sigmoid; total time=  29.1s\n",
      "[CV] END ..............C=0.001, epsilon=0.01, kernel=sigmoid; total time=  30.3s\n",
      "[CV] END ..............C=0.001, epsilon=0.01, kernel=sigmoid; total time=  33.2s\n",
      "[CV] END ..............C=0.001, epsilon=0.01, kernel=sigmoid; total time=  32.7s\n",
      "[CV] END ..................C=0.001, epsilon=0.1, kernel=poly; total time=  30.4s\n",
      "[CV] END ..................C=0.001, epsilon=0.1, kernel=poly; total time=  31.1s\n",
      "[CV] END ..................C=0.001, epsilon=0.1, kernel=poly; total time=  29.6s\n",
      "[CV] END ..................C=0.001, epsilon=0.1, kernel=poly; total time=  23.9s\n",
      "[CV] END ..................C=0.001, epsilon=0.1, kernel=poly; total time=  21.2s\n",
      "[CV] END ...................C=0.001, epsilon=0.1, kernel=rbf; total time=  21.9s\n",
      "[CV] END ...................C=0.001, epsilon=0.1, kernel=rbf; total time=  25.9s\n",
      "[CV] END ...................C=0.001, epsilon=0.1, kernel=rbf; total time=  22.5s\n",
      "[CV] END ...................C=0.001, epsilon=0.1, kernel=rbf; total time=  22.5s\n",
      "[CV] END ...................C=0.001, epsilon=0.1, kernel=rbf; total time=  22.7s\n",
      "[CV] END ...............C=0.001, epsilon=0.1, kernel=sigmoid; total time=  20.4s\n",
      "[CV] END ...............C=0.001, epsilon=0.1, kernel=sigmoid; total time=  21.3s\n",
      "[CV] END ...............C=0.001, epsilon=0.1, kernel=sigmoid; total time=  19.1s\n",
      "[CV] END ...............C=0.001, epsilon=0.1, kernel=sigmoid; total time=  18.8s\n",
      "[CV] END ...............C=0.001, epsilon=0.1, kernel=sigmoid; total time=  19.1s\n",
      "[CV] END ....................C=0.001, epsilon=1, kernel=poly; total time=   0.8s\n",
      "[CV] END ....................C=0.001, epsilon=1, kernel=poly; total time=   0.9s\n",
      "[CV] END ....................C=0.001, epsilon=1, kernel=poly; total time=   0.9s\n",
      "[CV] END ....................C=0.001, epsilon=1, kernel=poly; total time=   0.9s\n",
      "[CV] END ....................C=0.001, epsilon=1, kernel=poly; total time=   0.9s\n",
      "[CV] END .....................C=0.001, epsilon=1, kernel=rbf; total time=   1.0s\n",
      "[CV] END .....................C=0.001, epsilon=1, kernel=rbf; total time=   1.1s\n",
      "[CV] END .....................C=0.001, epsilon=1, kernel=rbf; total time=   1.1s\n",
      "[CV] END .....................C=0.001, epsilon=1, kernel=rbf; total time=   1.1s\n",
      "[CV] END .....................C=0.001, epsilon=1, kernel=rbf; total time=   1.0s\n",
      "[CV] END .................C=0.001, epsilon=1, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END .................C=0.001, epsilon=1, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END .................C=0.001, epsilon=1, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END .................C=0.001, epsilon=1, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END .................C=0.001, epsilon=1, kernel=sigmoid; total time=   0.7s\n",
      "[CV] END .................C=0.01, epsilon=0.001, kernel=poly; total time=  26.7s\n",
      "[CV] END .................C=0.01, epsilon=0.001, kernel=poly; total time=  27.2s\n",
      "[CV] END .................C=0.01, epsilon=0.001, kernel=poly; total time=  26.8s\n",
      "[CV] END .................C=0.01, epsilon=0.001, kernel=poly; total time=  27.4s\n",
      "[CV] END .................C=0.01, epsilon=0.001, kernel=poly; total time=  26.8s\n",
      "[CV] END ..................C=0.01, epsilon=0.001, kernel=rbf; total time=  29.7s\n",
      "[CV] END ..................C=0.01, epsilon=0.001, kernel=rbf; total time=  29.6s\n",
      "[CV] END ..................C=0.01, epsilon=0.001, kernel=rbf; total time=  30.8s\n",
      "[CV] END ..................C=0.01, epsilon=0.001, kernel=rbf; total time=  30.1s\n",
      "[CV] END ..................C=0.01, epsilon=0.001, kernel=rbf; total time=  30.0s\n",
      "[CV] END ..............C=0.01, epsilon=0.001, kernel=sigmoid; total time=  28.7s\n",
      "[CV] END ..............C=0.01, epsilon=0.001, kernel=sigmoid; total time=  27.5s\n",
      "[CV] END ..............C=0.01, epsilon=0.001, kernel=sigmoid; total time=  27.9s\n",
      "[CV] END ..............C=0.01, epsilon=0.001, kernel=sigmoid; total time=  27.7s\n",
      "[CV] END ..............C=0.01, epsilon=0.001, kernel=sigmoid; total time=  27.9s\n",
      "[CV] END ..................C=0.01, epsilon=0.01, kernel=poly; total time=  25.7s\n",
      "[CV] END ..................C=0.01, epsilon=0.01, kernel=poly; total time=  25.8s\n",
      "[CV] END ..................C=0.01, epsilon=0.01, kernel=poly; total time=  25.7s\n",
      "[CV] END ..................C=0.01, epsilon=0.01, kernel=poly; total time=  26.2s\n",
      "[CV] END ..................C=0.01, epsilon=0.01, kernel=poly; total time=  25.8s\n",
      "[CV] END ...................C=0.01, epsilon=0.01, kernel=rbf; total time=  28.3s\n",
      "[CV] END ...................C=0.01, epsilon=0.01, kernel=rbf; total time=  28.0s\n",
      "[CV] END ...................C=0.01, epsilon=0.01, kernel=rbf; total time=  28.3s\n",
      "[CV] END ...................C=0.01, epsilon=0.01, kernel=rbf; total time=  28.0s\n",
      "[CV] END ...................C=0.01, epsilon=0.01, kernel=rbf; total time=  28.0s\n",
      "[CV] END ...............C=0.01, epsilon=0.01, kernel=sigmoid; total time=  26.1s\n",
      "[CV] END ...............C=0.01, epsilon=0.01, kernel=sigmoid; total time=  26.3s\n",
      "[CV] END ...............C=0.01, epsilon=0.01, kernel=sigmoid; total time=  26.0s\n",
      "[CV] END ...............C=0.01, epsilon=0.01, kernel=sigmoid; total time=  26.1s\n",
      "[CV] END ...............C=0.01, epsilon=0.01, kernel=sigmoid; total time=  26.5s\n",
      "[CV] END ...................C=0.01, epsilon=0.1, kernel=poly; total time=  19.2s\n",
      "[CV] END ...................C=0.01, epsilon=0.1, kernel=poly; total time=  19.6s\n",
      "[CV] END ...................C=0.01, epsilon=0.1, kernel=poly; total time=  18.9s\n",
      "[CV] END ...................C=0.01, epsilon=0.1, kernel=poly; total time=  19.1s\n",
      "[CV] END ...................C=0.01, epsilon=0.1, kernel=poly; total time=  18.9s\n",
      "[CV] END ....................C=0.01, epsilon=0.1, kernel=rbf; total time=  15.9s\n",
      "[CV] END ....................C=0.01, epsilon=0.1, kernel=rbf; total time=  16.0s\n",
      "[CV] END ....................C=0.01, epsilon=0.1, kernel=rbf; total time=  15.8s\n",
      "[CV] END ....................C=0.01, epsilon=0.1, kernel=rbf; total time=  16.0s\n",
      "[CV] END ....................C=0.01, epsilon=0.1, kernel=rbf; total time=  16.0s\n",
      "[CV] END ................C=0.01, epsilon=0.1, kernel=sigmoid; total time=  14.3s\n",
      "[CV] END ................C=0.01, epsilon=0.1, kernel=sigmoid; total time=  13.8s\n",
      "[CV] END ................C=0.01, epsilon=0.1, kernel=sigmoid; total time=  13.4s\n",
      "[CV] END ................C=0.01, epsilon=0.1, kernel=sigmoid; total time=  13.7s\n",
      "[CV] END ................C=0.01, epsilon=0.1, kernel=sigmoid; total time=  13.8s\n",
      "[CV] END .....................C=0.01, epsilon=1, kernel=poly; total time=   0.6s\n",
      "[CV] END .....................C=0.01, epsilon=1, kernel=poly; total time=   0.6s\n",
      "[CV] END .....................C=0.01, epsilon=1, kernel=poly; total time=   0.7s\n",
      "[CV] END .....................C=0.01, epsilon=1, kernel=poly; total time=   0.6s\n",
      "[CV] END .....................C=0.01, epsilon=1, kernel=poly; total time=   0.8s\n",
      "[CV] END ......................C=0.01, epsilon=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ......................C=0.01, epsilon=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ......................C=0.01, epsilon=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ......................C=0.01, epsilon=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ......................C=0.01, epsilon=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ..................C=0.01, epsilon=1, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=0.01, epsilon=1, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=0.01, epsilon=1, kernel=sigmoid; total time=   0.4s\n",
      "[CV] END ..................C=0.01, epsilon=1, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=0.01, epsilon=1, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=0.1, epsilon=0.001, kernel=poly; total time=  27.2s\n",
      "[CV] END ..................C=0.1, epsilon=0.001, kernel=poly; total time=  27.5s\n",
      "[CV] END ..................C=0.1, epsilon=0.001, kernel=poly; total time=  27.2s\n",
      "[CV] END ..................C=0.1, epsilon=0.001, kernel=poly; total time=  27.1s\n",
      "[CV] END ..................C=0.1, epsilon=0.001, kernel=poly; total time=  27.1s\n",
      "[CV] END ...................C=0.1, epsilon=0.001, kernel=rbf; total time=  30.1s\n",
      "[CV] END ...................C=0.1, epsilon=0.001, kernel=rbf; total time=  30.3s\n",
      "[CV] END ...................C=0.1, epsilon=0.001, kernel=rbf; total time=  30.1s\n",
      "[CV] END ...................C=0.1, epsilon=0.001, kernel=rbf; total time=  30.3s\n",
      "[CV] END ...................C=0.1, epsilon=0.001, kernel=rbf; total time=  30.4s\n",
      "[CV] END ...............C=0.1, epsilon=0.001, kernel=sigmoid; total time=  29.0s\n",
      "[CV] END ...............C=0.1, epsilon=0.001, kernel=sigmoid; total time=  29.3s\n",
      "[CV] END ...............C=0.1, epsilon=0.001, kernel=sigmoid; total time=  29.1s\n",
      "[CV] END ...............C=0.1, epsilon=0.001, kernel=sigmoid; total time=  29.5s\n",
      "[CV] END ...............C=0.1, epsilon=0.001, kernel=sigmoid; total time=  29.0s\n",
      "[CV] END ...................C=0.1, epsilon=0.01, kernel=poly; total time=  25.8s\n",
      "[CV] END ...................C=0.1, epsilon=0.01, kernel=poly; total time=  25.9s\n",
      "[CV] END ...................C=0.1, epsilon=0.01, kernel=poly; total time=  25.8s\n",
      "[CV] END ...................C=0.1, epsilon=0.01, kernel=poly; total time=  25.7s\n",
      "[CV] END ...................C=0.1, epsilon=0.01, kernel=poly; total time=  29.9s\n",
      "[CV] END ....................C=0.1, epsilon=0.01, kernel=rbf; total time=  30.8s\n",
      "[CV] END ....................C=0.1, epsilon=0.01, kernel=rbf; total time=  29.9s\n",
      "[CV] END ....................C=0.1, epsilon=0.01, kernel=rbf; total time=  29.6s\n",
      "[CV] END ....................C=0.1, epsilon=0.01, kernel=rbf; total time=  29.2s\n",
      "[CV] END ....................C=0.1, epsilon=0.01, kernel=rbf; total time=  28.9s\n",
      "[CV] END ................C=0.1, epsilon=0.01, kernel=sigmoid; total time=  30.9s\n",
      "[CV] END ................C=0.1, epsilon=0.01, kernel=sigmoid; total time=  31.2s\n",
      "[CV] END ................C=0.1, epsilon=0.01, kernel=sigmoid; total time=  31.0s\n",
      "[CV] END ................C=0.1, epsilon=0.01, kernel=sigmoid; total time=  31.9s\n",
      "[CV] END ................C=0.1, epsilon=0.01, kernel=sigmoid; total time=  31.7s\n",
      "[CV] END ....................C=0.1, epsilon=0.1, kernel=poly; total time=  16.7s\n",
      "[CV] END ....................C=0.1, epsilon=0.1, kernel=poly; total time=  16.6s\n",
      "[CV] END ....................C=0.1, epsilon=0.1, kernel=poly; total time=  16.8s\n",
      "[CV] END ....................C=0.1, epsilon=0.1, kernel=poly; total time=  16.4s\n",
      "[CV] END ....................C=0.1, epsilon=0.1, kernel=poly; total time=  16.9s\n",
      "[CV] END .....................C=0.1, epsilon=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .....................C=0.1, epsilon=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .....................C=0.1, epsilon=0.1, kernel=rbf; total time=  10.1s\n",
      "[CV] END .....................C=0.1, epsilon=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .....................C=0.1, epsilon=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .................C=0.1, epsilon=0.1, kernel=sigmoid; total time=  28.9s\n",
      "[CV] END .................C=0.1, epsilon=0.1, kernel=sigmoid; total time=  28.9s\n",
      "[CV] END .................C=0.1, epsilon=0.1, kernel=sigmoid; total time=  28.7s\n",
      "[CV] END .................C=0.1, epsilon=0.1, kernel=sigmoid; total time=  29.6s\n",
      "[CV] END .................C=0.1, epsilon=0.1, kernel=sigmoid; total time=  29.1s\n",
      "[CV] END ......................C=0.1, epsilon=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=0.1, epsilon=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=0.1, epsilon=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=0.1, epsilon=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=0.1, epsilon=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=0.1, epsilon=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=0.1, epsilon=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=0.1, epsilon=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=0.1, epsilon=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=0.1, epsilon=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...................C=0.1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, epsilon=0.001, kernel=poly; total time=  48.4s\n",
      "[CV] END ....................C=1, epsilon=0.001, kernel=poly; total time=  42.9s\n",
      "[CV] END ....................C=1, epsilon=0.001, kernel=poly; total time=  47.0s\n",
      "[CV] END ....................C=1, epsilon=0.001, kernel=poly; total time=  47.7s\n",
      "[CV] END ....................C=1, epsilon=0.001, kernel=poly; total time=  47.8s\n",
      "[CV] END .....................C=1, epsilon=0.001, kernel=rbf; total time=  59.8s\n",
      "[CV] END .....................C=1, epsilon=0.001, kernel=rbf; total time=  59.1s\n",
      "[CV] END .....................C=1, epsilon=0.001, kernel=rbf; total time=  56.0s\n",
      "[CV] END .....................C=1, epsilon=0.001, kernel=rbf; total time=  56.8s\n",
      "[CV] END .....................C=1, epsilon=0.001, kernel=rbf; total time=  57.5s\n",
      "[CV] END .................C=1, epsilon=0.001, kernel=sigmoid; total time=  31.0s\n",
      "[CV] END .................C=1, epsilon=0.001, kernel=sigmoid; total time=  31.4s\n",
      "[CV] END .................C=1, epsilon=0.001, kernel=sigmoid; total time=  30.5s\n",
      "[CV] END .................C=1, epsilon=0.001, kernel=sigmoid; total time=  31.5s\n",
      "[CV] END .................C=1, epsilon=0.001, kernel=sigmoid; total time=  31.0s\n",
      "[CV] END .....................C=1, epsilon=0.01, kernel=poly; total time=  33.1s\n",
      "[CV] END .....................C=1, epsilon=0.01, kernel=poly; total time=  30.7s\n",
      "[CV] END .....................C=1, epsilon=0.01, kernel=poly; total time=  32.6s\n",
      "[CV] END .....................C=1, epsilon=0.01, kernel=poly; total time=  30.0s\n",
      "[CV] END .....................C=1, epsilon=0.01, kernel=poly; total time=  30.5s\n",
      "[CV] END ......................C=1, epsilon=0.01, kernel=rbf; total time=  40.4s\n",
      "[CV] END ......................C=1, epsilon=0.01, kernel=rbf; total time=  40.0s\n",
      "[CV] END ......................C=1, epsilon=0.01, kernel=rbf; total time=  39.1s\n",
      "[CV] END ......................C=1, epsilon=0.01, kernel=rbf; total time=  41.0s\n",
      "[CV] END ......................C=1, epsilon=0.01, kernel=rbf; total time=  41.3s\n",
      "[CV] END ..................C=1, epsilon=0.01, kernel=sigmoid; total time=  32.4s\n",
      "[CV] END ..................C=1, epsilon=0.01, kernel=sigmoid; total time=  31.9s\n",
      "[CV] END ..................C=1, epsilon=0.01, kernel=sigmoid; total time=  31.8s\n",
      "[CV] END ..................C=1, epsilon=0.01, kernel=sigmoid; total time=  32.0s\n",
      "[CV] END ..................C=1, epsilon=0.01, kernel=sigmoid; total time=  33.3s\n",
      "[CV] END ......................C=1, epsilon=0.1, kernel=poly; total time=  13.9s\n",
      "[CV] END ......................C=1, epsilon=0.1, kernel=poly; total time=  13.9s\n",
      "[CV] END ......................C=1, epsilon=0.1, kernel=poly; total time=  13.8s\n",
      "[CV] END ......................C=1, epsilon=0.1, kernel=poly; total time=  13.9s\n",
      "[CV] END ......................C=1, epsilon=0.1, kernel=poly; total time=  14.3s\n",
      "[CV] END .......................C=1, epsilon=0.1, kernel=rbf; total time=   8.5s\n",
      "[CV] END .......................C=1, epsilon=0.1, kernel=rbf; total time=   8.5s\n",
      "[CV] END .......................C=1, epsilon=0.1, kernel=rbf; total time=   8.8s\n",
      "[CV] END .......................C=1, epsilon=0.1, kernel=rbf; total time=   8.6s\n",
      "[CV] END .......................C=1, epsilon=0.1, kernel=rbf; total time=   8.5s\n",
      "[CV] END ...................C=1, epsilon=0.1, kernel=sigmoid; total time=  29.2s\n",
      "[CV] END ...................C=1, epsilon=0.1, kernel=sigmoid; total time=  29.2s\n",
      "[CV] END ...................C=1, epsilon=0.1, kernel=sigmoid; total time=  30.3s\n",
      "[CV] END ...................C=1, epsilon=0.1, kernel=sigmoid; total time=  28.8s\n",
      "[CV] END ...................C=1, epsilon=0.1, kernel=sigmoid; total time=  30.9s\n",
      "[CV] END ........................C=1, epsilon=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, epsilon=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, epsilon=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, epsilon=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, epsilon=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=1, epsilon=1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .........................C=1, epsilon=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=1, epsilon=1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .........................C=1, epsilon=1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .........................C=1, epsilon=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END .....................C=1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, epsilon=1, kernel=sigmoid; total time=   0.1s\n",
      "Miglior hyperparametro {'C': 1, 'epsilon': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svr= SVR()\n",
    "\n",
    "param_grid= {\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'epsilon': [0.001, 0.01, 0.1, 1],\n",
    "    'C': [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid_search= GridSearchCV(estimator= svr, param_grid= param_grid, cv=5, scoring='neg_mean_squared_error', verbose= 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_param= grid_search.best_params_\n",
    "print(\"Miglior hyperparametro\", best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca_t == True:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/pca/svr.csv\")\n",
    "else:\n",
    "    pd.DataFrame(grid_search.cv_results_).to_csv(f\"tradML/risultati_cv/no_pca/svr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(grid_search.cv_results_)\n",
    "results= results[['mean_test_score', 'param_kernel', 'param_epsilon', 'param_C']]\n",
    "results['mean_test_score']= -1*results['mean_test_score']\n",
    "\n",
    "if pca_t == True:\n",
    "    writer= SummaryWriter(f'risultati/Machine_Learning_trad/pca/SVR/')\n",
    "else:\n",
    "    writer= SummaryWriter(f'risultati/Machine_Learning_trad/no_pca/SVR/')\n",
    "for i, rows in results.iterrows():\n",
    "    mse= rows['mean_test_score']\n",
    "    kernel= rows['param_kernel']\n",
    "    epsilon= rows['param_epsilon']\n",
    "    c= rows['param_C']\n",
    "    writer.add_hparams({'C': c, 'epsilon': epsilon, 'kernel': kernel}, {'mse': mse})\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr= pd.DataFrame.from_dict(grid_search.best_params_, orient='index', columns=['value'])\n",
    "svr= svr.T\n",
    "if pca_t == True:\n",
    "    svr.to_csv('tradML/b_params/pca/svr.csv', index=False)\n",
    "else:\n",
    "    svr.to_csv('tradML/b_params/no_pca/svr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  0.00659967092004883\n",
      "R2 score:  0.9702269715302189\n"
     ]
    }
   ],
   "source": [
    "svr= SVR(kernel= best_param['kernel'], epsilon= best_param['epsilon'], C= best_param['C'])\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred= svr.predict(X_test)\n",
    "\n",
    "print(\"Mean squared error: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score: \", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
