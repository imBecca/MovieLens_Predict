{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "fix_random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_t = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('ml-25m/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tran set: 8841\n",
      "Number of val set: 2211\n",
      "Number of test set: 2764\n"
     ]
    }
   ],
   "source": [
    "X= df.drop(['rating'], axis=1).to_numpy()\n",
    "y= df['rating'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Number of tran set:\", X_train.shape[0])\n",
    "print(\"Number of val set:\", X_val.shape[0])\n",
    "print(\"Number of test set:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA is not applied\n"
     ]
    }
   ],
   "source": [
    "if pca_t == True:\n",
    "    pca= PCA(n_components= 0.95)\n",
    "    pca.fit(X_train)\n",
    "    X_train= pca.transform(X_train)\n",
    "    X_val= pca.transform(X_val)\n",
    "    X_test= pca.transform(X_test)\n",
    "    print(\"PCA is applied\")\n",
    "else:\n",
    "    print(\"PCA is not applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.array(X_train, dtype=np.float32)\n",
    "X_val= np.array(X_val, dtype=np.float32)\n",
    "X_test= np.array(X_test, dtype=np.float32)\n",
    "\n",
    "y_train= np.array(y_train, dtype=np.float32)\n",
    "y_val= np.array(y_val, dtype=np.float32)\n",
    "y_test= np.array(y_test, dtype=np.float32)\n",
    "\n",
    "val_dataloader= DataLoader(TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val)), batch_size= y_val.shape[0])\n",
    "test_dataloader= DataLoader(TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)), batch_size= y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, dept= 3, hidden_size= 64, dropout_prob= 0.2):\n",
    "    model= [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "    for i in range(dept):\n",
    "        model.append(nn.Linear(hidden_size, hidden_size))\n",
    "        model.append(nn.ReLU())\n",
    "        model.append(nn.Dropout(dropout_prob))\n",
    "    model.append(nn.Linear(hidden_size, 1))\n",
    "    return nn.Sequential(*model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 144\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "hidden_size= [64, 128, 256, 512]\n",
    "dropout_prob= [0.2, 0.3]\n",
    "dept= [3, 4, 5]\n",
    "epochs= [200]\n",
    "batch_size= [8, 16, 32]\n",
    "lr= [0.001, 0.01]\n",
    "\n",
    "# itertools\n",
    "params = product(hidden_size, dropout_prob, dept, batch_size, lr)\n",
    "combinations = len(hidden_size) * len(dropout_prob) * len(dept) * len(batch_size) * len(lr)\n",
    "print(\"Number of combinations:\", combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, writer, train_dataloader, val_dataloader, device, epochs= 100, hidden_size= 3, dropout_prob= 0.2, dept= 2, batch_size= 32, lr= 0.001):\n",
    "    best_model= None\n",
    "    best_loss= np.inf\n",
    "    patience= 10\n",
    "    p_counter= 0\n",
    "\n",
    "    train_loss= []\n",
    "    val_loss= []\n",
    "\n",
    "    criterion= nn.MSELoss()\n",
    "    optimizer= optim.Adam(model.parameters(), lr= lr)\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_start= time.time()\n",
    "        epoch_loss= 0.0\n",
    "\n",
    "        for x, y in train_dataloader:\n",
    "            x= x.to(device)\n",
    "            y= y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred= model(x)\n",
    "            loss= criterion(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss+= loss.item()\n",
    "\n",
    "        train_loss.append(epoch_loss/len(train_dataloader))\n",
    "\n",
    "        model.eval()\n",
    "        epoch_val_loss= 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_dataloader:\n",
    "                x= x.to(device)\n",
    "                y= y.to(device)\n",
    "\n",
    "                y_pred= model(x)\n",
    "                loss= criterion(y_pred, y.unsqueeze(1))\n",
    "                epoch_val_loss+= loss.item()\n",
    "        val_loss.append(epoch_val_loss/len(val_dataloader))\n",
    "\n",
    "        writer.add_scalar('Loss/train', train_loss[-1], epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss[-1], epoch)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {train_loss[-1]:.4f}, Val Loss: {val_loss[-1]:.4f}, Time: {time.time()-epoch_start:.2f}s')\n",
    "\n",
    "        if val_loss[-1] < best_loss:\n",
    "            best_loss= val_loss[-1]\n",
    "            best_model= copy.deepcopy(model)\n",
    "            p_counter= 0\n",
    "        else:\n",
    "            p_counter+= 1\n",
    "            if patience == p_counter:\n",
    "                break\n",
    "    \n",
    "    print('Trauing in {} epochs with best val loss:{}'. format(len(train_loss), best_loss))\n",
    "\n",
    "    return best_model, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "    y_pred= []\n",
    "    y_true= []\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dataloader:\n",
    "            x= x.to(device)\n",
    "            y= y.to(device)\n",
    "\n",
    "            y_pred.extend(model(x).squeeze(1).tolist())\n",
    "            y_true.extend(y.tolist())\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/[200], Loss: 0.4582, Val Loss: 0.0784, Time: 6.85s\n",
      "Trauing in 1 epochs with best val loss:0.07842180132865906\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 2/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.2423, Val Loss: 0.0320, Time: 4.05s\n",
      "Trauing in 1 epochs with best val loss:0.03195612132549286\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 3/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.7549, Val Loss: 0.0764, Time: 1.94s\n",
      "Trauing in 1 epochs with best val loss:0.07644930481910706\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 4/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.6060, Val Loss: 0.0875, Time: 2.48s\n",
      "Trauing in 1 epochs with best val loss:0.08751649409532547\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 5/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 1.1655, Val Loss: 0.1459, Time: 1.44s\n",
      "Trauing in 1 epochs with best val loss:0.14593851566314697\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 6/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.4983, Val Loss: 0.0386, Time: 0.96s\n",
      "Trauing in 1 epochs with best val loss:0.038579847663640976\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 7/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4991, Val Loss: 0.0270, Time: 6.14s\n",
      "Trauing in 1 epochs with best val loss:0.026989253237843513\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 8/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.2192, Val Loss: 0.0266, Time: 4.68s\n",
      "Trauing in 1 epochs with best val loss:0.02655191160738468\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 9/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.7689, Val Loss: 0.0439, Time: 2.14s\n",
      "Trauing in 1 epochs with best val loss:0.043869223445653915\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 10/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.2648, Val Loss: 0.0780, Time: 2.06s\n",
      "Trauing in 1 epochs with best val loss:0.07798083126544952\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 11/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 1.1138, Val Loss: 0.1441, Time: 1.08s\n",
      "Trauing in 1 epochs with best val loss:0.14405208826065063\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 12/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3477, Val Loss: 0.0265, Time: 1.48s\n",
      "Trauing in 1 epochs with best val loss:0.02652548812329769\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 13/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5023, Val Loss: 0.0535, Time: 6.75s\n",
      "Trauing in 1 epochs with best val loss:0.05347875505685806\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 14/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3213, Val Loss: 0.0354, Time: 5.90s\n",
      "Trauing in 1 epochs with best val loss:0.03538908436894417\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 15/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.7218, Val Loss: 0.0351, Time: 2.65s\n",
      "Trauing in 1 epochs with best val loss:0.035102132707834244\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 16/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.6951, Val Loss: 0.0436, Time: 2.25s\n",
      "Trauing in 1 epochs with best val loss:0.04364316910505295\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 17/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 1.1565, Val Loss: 0.2262, Time: 0.95s\n",
      "Trauing in 1 epochs with best val loss:0.22616074979305267\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 18/144\n",
      "hidden_size: 64, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3790, Val Loss: 0.0225, Time: 1.55s\n",
      "Trauing in 1 epochs with best val loss:0.022464849054813385\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 19/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.6616, Val Loss: 0.1648, Time: 3.04s\n",
      "Trauing in 1 epochs with best val loss:0.16477300226688385\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 20/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3448, Val Loss: 0.0348, Time: 3.66s\n",
      "Trauing in 1 epochs with best val loss:0.03476715832948685\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 21/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.7922, Val Loss: 0.2100, Time: 1.87s\n",
      "Trauing in 1 epochs with best val loss:0.21001775562763214\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 22/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5924, Val Loss: 0.0378, Time: 1.81s\n",
      "Trauing in 1 epochs with best val loss:0.037776198238134384\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 23/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 1.3378, Val Loss: 0.0924, Time: 0.80s\n",
      "Trauing in 1 epochs with best val loss:0.0924045667052269\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 24/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5582, Val Loss: 0.0465, Time: 0.96s\n",
      "Trauing in 1 epochs with best val loss:0.04646593704819679\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 25/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.6319, Val Loss: 0.0943, Time: 3.25s\n",
      "Trauing in 1 epochs with best val loss:0.09429340064525604\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 26/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.4367, Val Loss: 0.0334, Time: 3.22s\n",
      "Trauing in 1 epochs with best val loss:0.033374007791280746\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 27/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.9035, Val Loss: 0.0729, Time: 2.47s\n",
      "Trauing in 1 epochs with best val loss:0.07287246733903885\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 28/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.6136, Val Loss: 0.0542, Time: 1.67s\n",
      "Trauing in 1 epochs with best val loss:0.05417892336845398\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 29/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 1.4834, Val Loss: 0.6232, Time: 0.84s\n",
      "Trauing in 1 epochs with best val loss:0.6232149004936218\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 30/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.4589, Val Loss: 0.0545, Time: 0.96s\n",
      "Trauing in 1 epochs with best val loss:0.05453088879585266\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 31/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.6567, Val Loss: 0.1097, Time: 4.55s\n",
      "Trauing in 1 epochs with best val loss:0.10970386117696762\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 32/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3446, Val Loss: 0.0640, Time: 5.05s\n",
      "Trauing in 1 epochs with best val loss:0.0640261098742485\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 33/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.9138, Val Loss: 0.1107, Time: 2.23s\n",
      "Trauing in 1 epochs with best val loss:0.11070828139781952\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 34/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3973, Val Loss: 0.1051, Time: 1.93s\n",
      "Trauing in 1 epochs with best val loss:0.10506906360387802\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 35/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 1.3820, Val Loss: 0.4423, Time: 1.28s\n",
      "Trauing in 1 epochs with best val loss:0.4422767162322998\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 36/144\n",
      "hidden_size: 64, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 1.3016, Val Loss: 0.1432, Time: 1.46s\n",
      "Trauing in 1 epochs with best val loss:0.14320476353168488\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 37/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3012, Val Loss: 0.0251, Time: 5.57s\n",
      "Trauing in 1 epochs with best val loss:0.025067096576094627\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 38/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.2247, Val Loss: 0.0516, Time: 4.61s\n",
      "Trauing in 1 epochs with best val loss:0.05161420628428459\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 39/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4801, Val Loss: 0.0472, Time: 1.98s\n",
      "Trauing in 1 epochs with best val loss:0.04721829295158386\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 40/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5222, Val Loss: 0.0225, Time: 2.04s\n",
      "Trauing in 1 epochs with best val loss:0.022541861981153488\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 41/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.7335, Val Loss: 0.0626, Time: 1.04s\n",
      "Trauing in 1 epochs with best val loss:0.06256956607103348\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 42/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.4873, Val Loss: 0.0306, Time: 0.95s\n",
      "Trauing in 1 epochs with best val loss:0.030632657930254936\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 43/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3795, Val Loss: 0.0224, Time: 5.53s\n",
      "Trauing in 1 epochs with best val loss:0.022445663809776306\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 44/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3718, Val Loss: 0.0230, Time: 9.26s\n",
      "Trauing in 1 epochs with best val loss:0.023042893037199974\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 45/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5141, Val Loss: 0.0211, Time: 3.01s\n",
      "Trauing in 1 epochs with best val loss:0.021134158596396446\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 46/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.7832, Val Loss: 0.0525, Time: 2.90s\n",
      "Trauing in 1 epochs with best val loss:0.05245178937911987\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 47/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.8268, Val Loss: 0.0627, Time: 1.72s\n",
      "Trauing in 1 epochs with best val loss:0.0626552402973175\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 48/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.9455, Val Loss: 0.0750, Time: 1.68s\n",
      "Trauing in 1 epochs with best val loss:0.07501967251300812\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 49/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3623, Val Loss: 0.0263, Time: 7.24s\n",
      "Trauing in 1 epochs with best val loss:0.026266051456332207\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 50/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.2664, Val Loss: 0.0360, Time: 8.35s\n",
      "Trauing in 1 epochs with best val loss:0.03603950887918472\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 51/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5084, Val Loss: 0.0485, Time: 3.35s\n",
      "Trauing in 1 epochs with best val loss:0.048540130257606506\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 52/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3836, Val Loss: 0.0369, Time: 3.27s\n",
      "Trauing in 1 epochs with best val loss:0.036864835768938065\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 53/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.7915, Val Loss: 0.0711, Time: 1.92s\n",
      "Trauing in 1 epochs with best val loss:0.07109364867210388\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 54/144\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 1.0579, Val Loss: 0.0435, Time: 1.76s\n",
      "Trauing in 1 epochs with best val loss:0.043450094759464264\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 55/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4232, Val Loss: 0.0576, Time: 5.82s\n",
      "Trauing in 1 epochs with best val loss:0.057629648596048355\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 56/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3033, Val Loss: 0.0369, Time: 6.57s\n",
      "Trauing in 1 epochs with best val loss:0.03693666681647301\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 57/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4948, Val Loss: 0.0271, Time: 1.99s\n",
      "Trauing in 1 epochs with best val loss:0.027065522968769073\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 58/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.4979, Val Loss: 0.0389, Time: 2.85s\n",
      "Trauing in 1 epochs with best val loss:0.038935255259275436\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 59/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.8059, Val Loss: 0.1463, Time: 1.56s\n",
      "Trauing in 1 epochs with best val loss:0.14629200100898743\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 60/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 1.0864, Val Loss: 0.0821, Time: 1.54s\n",
      "Trauing in 1 epochs with best val loss:0.08209901303052902\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 61/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4481, Val Loss: 0.0280, Time: 6.58s\n",
      "Trauing in 1 epochs with best val loss:0.027960143983364105\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 62/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3877, Val Loss: 0.0631, Time: 7.31s\n",
      "Trauing in 1 epochs with best val loss:0.0630749762058258\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 63/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5514, Val Loss: 0.0706, Time: 2.74s\n",
      "Trauing in 1 epochs with best val loss:0.07057496160268784\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 64/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.8022, Val Loss: 0.0326, Time: 3.09s\n",
      "Trauing in 1 epochs with best val loss:0.032619085162878036\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 65/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.8391, Val Loss: 0.0489, Time: 1.59s\n",
      "Trauing in 1 epochs with best val loss:0.04894553869962692\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 66/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.8841, Val Loss: 0.0870, Time: 1.73s\n",
      "Trauing in 1 epochs with best val loss:0.08696732670068741\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 67/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4162, Val Loss: 0.0315, Time: 8.25s\n",
      "Trauing in 1 epochs with best val loss:0.03148854151368141\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 68/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.2925, Val Loss: 0.1144, Time: 8.34s\n",
      "Trauing in 1 epochs with best val loss:0.11441154778003693\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 69/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.6125, Val Loss: 0.0518, Time: 3.33s\n",
      "Trauing in 1 epochs with best val loss:0.05175584554672241\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 70/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.7824, Val Loss: 0.0495, Time: 3.91s\n",
      "Trauing in 1 epochs with best val loss:0.049503739923238754\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 71/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 1.0656, Val Loss: 0.1639, Time: 1.39s\n",
      "Trauing in 1 epochs with best val loss:0.16390566527843475\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 72/144\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 1.1333, Val Loss: 0.0784, Time: 1.41s\n",
      "Trauing in 1 epochs with best val loss:0.07839548587799072\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 73/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2515, Val Loss: 0.0188, Time: 10.45s\n",
      "Trauing in 1 epochs with best val loss:0.018789933994412422\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 74/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3443, Val Loss: 0.0270, Time: 11.03s\n",
      "Trauing in 1 epochs with best val loss:0.027023084461688995\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 75/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3082, Val Loss: 0.0229, Time: 4.13s\n",
      "Trauing in 1 epochs with best val loss:0.022878333926200867\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 76/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.6653, Val Loss: 0.0363, Time: 4.11s\n",
      "Trauing in 1 epochs with best val loss:0.03634420037269592\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 77/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5122, Val Loss: 0.1699, Time: 2.21s\n",
      "Trauing in 1 epochs with best val loss:0.16992081701755524\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 78/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.6639, Val Loss: 0.0406, Time: 2.41s\n",
      "Trauing in 1 epochs with best val loss:0.040600720793008804\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 79/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2546, Val Loss: 0.0196, Time: 10.96s\n",
      "Trauing in 1 epochs with best val loss:0.019571496173739433\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 80/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 5.7224, Val Loss: 0.2411, Time: 12.20s\n",
      "Trauing in 1 epochs with best val loss:0.24107196927070618\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 81/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3564, Val Loss: 0.0635, Time: 4.31s\n",
      "Trauing in 1 epochs with best val loss:0.06349453330039978\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 82/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.3703, Val Loss: 0.0327, Time: 4.47s\n",
      "Trauing in 1 epochs with best val loss:0.03269709274172783\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 83/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5414, Val Loss: 0.0557, Time: 2.65s\n",
      "Trauing in 1 epochs with best val loss:0.05568085238337517\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 84/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 1.0244, Val Loss: 0.0363, Time: 2.59s\n",
      "Trauing in 1 epochs with best val loss:0.03631408140063286\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 85/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2868, Val Loss: 0.0232, Time: 14.79s\n",
      "Trauing in 1 epochs with best val loss:0.023164942860603333\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 86/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 10.1067, Val Loss: 0.0960, Time: 13.81s\n",
      "Trauing in 1 epochs with best val loss:0.09598524868488312\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 87/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3706, Val Loss: 0.0234, Time: 5.16s\n",
      "Trauing in 1 epochs with best val loss:0.02344127558171749\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 88/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.7490, Val Loss: 0.0412, Time: 4.90s\n",
      "Trauing in 1 epochs with best val loss:0.04120117425918579\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 89/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5251, Val Loss: 0.0315, Time: 3.21s\n",
      "Trauing in 1 epochs with best val loss:0.03153669089078903\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 90/144\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5574, Val Loss: 0.0714, Time: 2.17s\n",
      "Trauing in 1 epochs with best val loss:0.07138290256261826\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 91/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3028, Val Loss: 0.1174, Time: 9.07s\n",
      "Trauing in 1 epochs with best val loss:0.11743120104074478\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 92/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.2604, Val Loss: 0.0925, Time: 10.95s\n",
      "Trauing in 1 epochs with best val loss:0.09247218072414398\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 93/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3655, Val Loss: 0.0192, Time: 4.15s\n",
      "Trauing in 1 epochs with best val loss:0.019244568422436714\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 94/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5403, Val Loss: 0.0332, Time: 3.85s\n",
      "Trauing in 1 epochs with best val loss:0.033210404217243195\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 95/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5551, Val Loss: 0.0428, Time: 2.34s\n",
      "Trauing in 1 epochs with best val loss:0.04281046241521835\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 96/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5268, Val Loss: 0.0325, Time: 2.23s\n",
      "Trauing in 1 epochs with best val loss:0.03250569850206375\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 97/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2924, Val Loss: 0.0273, Time: 11.21s\n",
      "Trauing in 1 epochs with best val loss:0.027310572564601898\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 98/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.7508, Val Loss: 0.0673, Time: 12.11s\n",
      "Trauing in 1 epochs with best val loss:0.06728368252515793\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 99/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4380, Val Loss: 0.0293, Time: 4.29s\n",
      "Trauing in 1 epochs with best val loss:0.029277127236127853\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 100/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 4.7715, Val Loss: 0.0784, Time: 4.46s\n",
      "Trauing in 1 epochs with best val loss:0.07838790863752365\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 101/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5505, Val Loss: 0.0995, Time: 2.45s\n",
      "Trauing in 1 epochs with best val loss:0.0995144173502922\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 102/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5871, Val Loss: 0.0396, Time: 2.97s\n",
      "Trauing in 1 epochs with best val loss:0.03956213220953941\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 103/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3231, Val Loss: 0.0224, Time: 12.05s\n",
      "Trauing in 1 epochs with best val loss:0.022399747744202614\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 104/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 9.8822, Val Loss: 0.0854, Time: 13.61s\n",
      "Trauing in 1 epochs with best val loss:0.08539190143346786\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 105/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4152, Val Loss: 0.0347, Time: 4.98s\n",
      "Trauing in 1 epochs with best val loss:0.03473631292581558\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 106/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.4570, Val Loss: 0.0859, Time: 5.03s\n",
      "Trauing in 1 epochs with best val loss:0.08594638109207153\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 107/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.7061, Val Loss: 0.0948, Time: 2.87s\n",
      "Trauing in 1 epochs with best val loss:0.09483733773231506\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 108/144\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 65.9518, Val Loss: 0.1890, Time: 3.28s\n",
      "Trauing in 1 epochs with best val loss:0.18896038830280304\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 109/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.1756, Val Loss: 0.0231, Time: 24.50s\n",
      "Trauing in 1 epochs with best val loss:0.02306765876710415\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 110/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 1.0530, Val Loss: 0.0506, Time: 26.04s\n",
      "Trauing in 1 epochs with best val loss:0.05057572200894356\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 111/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2568, Val Loss: 0.0205, Time: 8.41s\n",
      "Trauing in 1 epochs with best val loss:0.020542679354548454\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 112/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 3.8376, Val Loss: 0.0386, Time: 8.76s\n",
      "Trauing in 1 epochs with best val loss:0.038631170988082886\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 113/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4435, Val Loss: 0.0323, Time: 5.04s\n",
      "Trauing in 1 epochs with best val loss:0.032265499234199524\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 114/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 7.5875, Val Loss: 0.0353, Time: 4.92s\n",
      "Trauing in 1 epochs with best val loss:0.03531075641512871\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 115/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.1897, Val Loss: 0.0586, Time: 27.72s\n",
      "Trauing in 1 epochs with best val loss:0.05862459912896156\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 116/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 3.0019, Val Loss: 0.0439, Time: 26.56s\n",
      "Trauing in 1 epochs with best val loss:0.0439351387321949\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 117/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2609, Val Loss: 0.0238, Time: 10.03s\n",
      "Trauing in 1 epochs with best val loss:0.023814883083105087\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 118/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 12.4192, Val Loss: 0.0645, Time: 12.63s\n",
      "Trauing in 1 epochs with best val loss:0.06447289139032364\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 119/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.5733, Val Loss: 0.0664, Time: 7.65s\n",
      "Trauing in 1 epochs with best val loss:0.06635129451751709\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 120/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 75.2216, Val Loss: 0.0660, Time: 10.65s\n",
      "Trauing in 1 epochs with best val loss:0.06596434861421585\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 121/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2045, Val Loss: 0.0316, Time: 34.17s\n",
      "Trauing in 1 epochs with best val loss:0.03156609833240509\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 122/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 4.8368, Val Loss: 0.0929, Time: 25.91s\n",
      "Trauing in 1 epochs with best val loss:0.09293118864297867\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 123/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2225, Val Loss: 0.0245, Time: 12.17s\n",
      "Trauing in 1 epochs with best val loss:0.024461491033434868\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 124/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 11.8131, Val Loss: 0.0494, Time: 12.71s\n",
      "Trauing in 1 epochs with best val loss:0.049356963485479355\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 125/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.6244, Val Loss: 0.0510, Time: 8.20s\n",
      "Trauing in 1 epochs with best val loss:0.05100410431623459\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 126/144\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 52.2483, Val Loss: 0.0455, Time: 8.14s\n",
      "Trauing in 1 epochs with best val loss:0.04550576210021973\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 127/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2339, Val Loss: 0.0495, Time: 23.50s\n",
      "Trauing in 1 epochs with best val loss:0.049513693898916245\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 128/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 0.5812, Val Loss: 0.0773, Time: 26.18s\n",
      "Trauing in 1 epochs with best val loss:0.07726900279521942\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 129/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2812, Val Loss: 0.0524, Time: 9.08s\n",
      "Trauing in 1 epochs with best val loss:0.052396271377801895\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 130/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 2.6024, Val Loss: 0.0473, Time: 8.76s\n",
      "Trauing in 1 epochs with best val loss:0.047312770038843155\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 131/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4732, Val Loss: 0.0633, Time: 4.96s\n",
      "Trauing in 1 epochs with best val loss:0.0632656067609787\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 132/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 6.5348, Val Loss: 0.0631, Time: 5.03s\n",
      "Trauing in 1 epochs with best val loss:0.06308433413505554\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 133/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2296, Val Loss: 0.0211, Time: 25.16s\n",
      "Trauing in 1 epochs with best val loss:0.021140869706869125\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 134/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 1.6337, Val Loss: 0.0555, Time: 30.32s\n",
      "Trauing in 1 epochs with best val loss:0.055528998374938965\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 135/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2931, Val Loss: 0.0168, Time: 10.48s\n",
      "Trauing in 1 epochs with best val loss:0.01678622141480446\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 136/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 2.3923, Val Loss: 0.0483, Time: 10.35s\n",
      "Trauing in 1 epochs with best val loss:0.048320189118385315\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 137/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.6150, Val Loss: 0.0280, Time: 6.77s\n",
      "Trauing in 1 epochs with best val loss:0.02798422984778881\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 138/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 18.9681, Val Loss: 0.0784, Time: 7.02s\n",
      "Trauing in 1 epochs with best val loss:0.07841731607913971\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 139/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.2572, Val Loss: 0.0470, Time: 33.46s\n",
      "Trauing in 1 epochs with best val loss:0.04696456342935562\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 140/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 8, lr: 0.01\n",
      "Epoch 201/[200], Loss: 2.0311, Val Loss: 0.2518, Time: 31.70s\n",
      "Trauing in 1 epochs with best val loss:0.25181397795677185\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 141/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.3747, Val Loss: 0.0355, Time: 11.83s\n",
      "Trauing in 1 epochs with best val loss:0.03546031937003136\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 142/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 16, lr: 0.01\n",
      "Epoch 201/[200], Loss: 12.9778, Val Loss: 0.1633, Time: 12.09s\n",
      "Trauing in 1 epochs with best val loss:0.1633271723985672\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 143/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.001\n",
      "Epoch 201/[200], Loss: 0.4446, Val Loss: 0.0220, Time: 8.17s\n",
      "Trauing in 1 epochs with best val loss:0.021954549476504326\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n",
      "Iteration 144/144\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 32, lr: 0.01\n",
      "Epoch 201/[200], Loss: 33.2571, Val Loss: 0.0587, Time: 8.01s\n",
      "Trauing in 1 epochs with best val loss:0.058720506727695465\n",
      "Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}\n"
     ]
    }
   ],
   "source": [
    "best_model= None\n",
    "best_loss= np.inf\n",
    "best_combination= None\n",
    "iteration= 0\n",
    "\n",
    "for hidden_size, dropout_prob, dept, batch_size, lr in params:\n",
    "    iteration+= 1\n",
    "    print(f'Iteration {iteration}/{combinations}')\n",
    "    print(f'hidden_size: {hidden_size}, dropout_prob: {dropout_prob}, dept: {dept}, batch_size: {batch_size}, lr: {lr}')\n",
    "\n",
    "    log= f'hidden_size: {hidden_size}, dropout_prob: {dropout_prob}, dept: {dept}, batch_size: {batch_size}, lr: {lr}'\n",
    "\n",
    "    if pca_t == True:\n",
    "        if os.path.exists('risultati/nn/pca'+log):\n",
    "            print('Model alredy trained. Skipping...')\n",
    "            continue\n",
    "        writer= SummaryWriter('risultati/nn/pca/'+log)\n",
    "    else:\n",
    "        if os.path.exists('risultati/nn/no_pca/'+log):\n",
    "            print('Model alredy trained. Skipping...')\n",
    "            continue\n",
    "        writer= SummaryWriter('risultati/nn/no_pca'+log)\n",
    "\n",
    "    model= get_model(X_train.shape[1], dept= dept, hidden_size= hidden_size, dropout_prob= dropout_prob)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)), batch_size= batch_size, shuffle= True)\n",
    "\n",
    "    config= {'hidden_size': hidden_size, \n",
    "             'dropout_prob': dropout_prob, \n",
    "             'dept': dept, \n",
    "             'batch_size': batch_size, \n",
    "             'lr': lr}\n",
    "    \n",
    "    model, train_loss, val_loss = train(model, writer, train_loader, val_dataloader, device, epochs, **config)\n",
    "\n",
    "    y_pred, y_true= test_model(model, test_dataloader, device)\n",
    "    test_loss= mean_squared_error(y_true, y_pred)\n",
    "    print('Test loss: {test_loss:.4f} - Best loss: {best_loss:.4f}')\n",
    "\n",
    "    writer.add_hparams(config, {'hparam/test_loss': test_loss})\n",
    "    writer.flush()\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss= test_loss\n",
    "        best_model= model\n",
    "        best_combination= config\n",
    "    \n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination: {'hidden_size': 512, 'dropout_prob': 0.3, 'dept': 4, 'batch_size': 16, 'lr': 0.001}\n",
      "Best loss: 0.01622953643687759\n"
     ]
    }
   ],
   "source": [
    "print('Best combination:', best_combination)\n",
    "print('Best loss:', best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01622953643687759\n",
      "R2: 0.9010470547932781\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true= test_model(best_model, test_dataloader, device)\n",
    "\n",
    "mse= mean_squared_error(y_true, y_pred)\n",
    "r2= r2_score(y_true, y_pred)\n",
    "\n",
    "print('MSE:', mse)\n",
    "print('R2:', r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
